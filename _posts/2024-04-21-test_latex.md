---
title: 'Latex test'
date: 2024-04-21
permalink: /posts/2024/04/latex-test/
tags:
  - math
---

Cross Entropy Loss
======
We can ce loss as
$$
H(y, \hat{y}) = - \sum_{i} y_i \log(\hat{y}_i)
$$
